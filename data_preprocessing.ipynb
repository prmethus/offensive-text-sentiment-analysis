{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739c5207-6368-461d-bd53-f0fdd6d04164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette(\"mako\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "857de45a-bdeb-4211-886b-15beffe7d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import download_dataset, join_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88795a20-269c-49a2-b7e0-10f04e0edf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dataset already exists!\n"
     ]
    }
   ],
   "source": [
    "download_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b674f1f-1923-4a2b-a287-bf23d40adceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03160c6f-c624-43ec-8c1f-14cfc7472b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_directory = \"cyberbully_datasets\"\n",
    "datasets = glob.glob(os.path.join(datasets_directory, \"*.csv\"))\n",
    "dataframe = pd.concat(list(map(lambda dataset: pd.read_csv(dataset)[[\"Text\", \"oh_label\"]], datasets)),axis=0)\n",
    "dataframe = dataframe.rename(columns={\"oh_label\":\"Offensive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d0285e9-baf3-457f-9c45-dcea6431ca9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    391223\n",
       "1.0     57651\n",
       "Name: Offensive, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[\"Offensive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54432e61-05f9-41b6-8beb-f25a6a50d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems like most of the texts we have aren't offensive. We can use Stratified Sampling for splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1497606-aabd-49c5-8dc3-f4b2e03275a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stratified_sampling_train_test_validation(sentences, labels):\n",
    "    \n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "    \n",
    "    s1 = StratifiedShuffleSplit(n_splits=2, test_size=0.2, random_state=0)\n",
    "    s2 = StratifiedShuffleSplit(n_splits=2, test_size=0.5, random_state=0)\n",
    "    \n",
    "    for train_index, test_valid_index in s1.split(sentences, labels):\n",
    "        sentences_for_training, labels_for_training = sentences[train_index], labels[train_index]\n",
    "        sentences_for_testing_valid, labels_for_testing_valid = sentences[test_valid_index], labels[test_valid_index]\n",
    "        \n",
    "    for validation_index, test_index in s2.split(sentences_for_testing_valid, labels_for_testing_valid):\n",
    "        sentences_for_validation, labels_for_validation = sentences_for_testing_valid[validation_index], labels[validation_index]\n",
    "        sentences_for_testing, labels_for_testing = sentences_for_testing_valid[test_index], labels[test_index]\n",
    "        \n",
    "        return (sentences_for_training, labels_for_training), (sentences_for_validation, labels_for_validation), (sentences_for_testing, labels_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "604152ec-f820-48f2-94f1-bd92c7860966",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = dataframe[\"Text\"]\n",
    "output = dataframe[\"Offensive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "035bcc2e-38dc-46da-bbb0-eec87b1ba312",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstratified_sampling_train_test_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mstratified_sampling_train_test_validation\u001b[0;34m(sentences, labels)\u001b[0m\n\u001b[1;32m      5\u001b[0m s1 \u001b[38;5;241m=\u001b[39m StratifiedShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m s2 \u001b[38;5;241m=\u001b[39m StratifiedShuffleSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_valid_index \u001b[38;5;129;01min\u001b[39;00m \u001b[43ms1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      9\u001b[0m     sentences_for_training, labels_for_training \u001b[38;5;241m=\u001b[39m sentences[train_index], labels[train_index]\n\u001b[1;32m     10\u001b[0m     sentences_for_testing_valid, labels_for_testing_valid \u001b[38;5;241m=\u001b[39m sentences[test_valid_index], labels[test_valid_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2022\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1989\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \n\u001b[1;32m   1991\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2020\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[1;32m   2021\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2022\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "stratified_sampling_train_test_validation(texts, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c317d9a-2511-4931-a742-ee1d15fbd42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
